# -*- coding: utf-8 -*-
"""FinalTask_IDX Partners_Data Scientist_Muhammad Zidan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ULq3ZU4gKTiLnzNesN5IMVd5dUcW-__h
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/drive/MyDrive/loan_data_2007_2014.csv')

"""# Data Understanding

## Menggunakan .head() untuk melihat 5 entry pertama dari data
"""

pd.set_option('display.max_columns', None)

pd.set_option('display.max_rows', None)

df.head().T

"""## Menggunakan .info() untuk melihat informasi tentang dataset"""

df.info()

"""## Drop fitur yang tidak berguna"""

df_clean = df.drop(df.columns[[0, 1, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 11, 19, 20]], axis=1)

df_clean.head(6
              ).T

"""## Melakukan Eksplorasi Awal Data"""

df.describe()

"""# Exploratory Data Analysis

## Analisis Univariat

### Menganalisa Variabel Target (loan_status)
"""

df_clean['loan_status'].value_counts()

loan_status_counts = df_clean['loan_status'].value_counts().reset_index()
loan_status_counts.columns = ['loan_status', 'count']

plt.figure(figsize=(10, 8))
sns.barplot(x='count', y='loan_status', data=loan_status_counts,
            palette='flare',
            orient='h')

plt.title('Count of Different Loan Statuses')
plt.xlabel('Count')
plt.ylabel('Loan Status')
plt.show()

"""### loan_amt"""

plt.figure(figsize=(10, 6))
sns.histplot(df['loan_amnt'])
plt.title('Distribution of Loan Amounts')
plt.xlabel('Loan Amount')
plt.ylabel('Frequency')
plt.show()

"""### Interest Rates"""

plt.figure(figsize=(10, 6))
sns.histplot(df['int_rate'], kde=True, color='green')
plt.title('Distribution of Interest Rates')
plt.xlabel('Interest Rate')
plt.ylabel('Frequency')
plt.show()

"""### Annual Income"""

plt.figure(figsize=(10, 6))
sns.histplot(df[df['annual_inc'] < 400000]['annual_inc'], bins=30, kde=True, color='red')
plt.title('Distribution of Annual Income')
plt.xlabel('Annual Income')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(df['annual_inc'], bins= 200, color='red')
plt.title('Distribution of Annual Income')
plt.xlabel('Annual Income')
plt.ylabel('Frequency')
plt.show()



"""Karena Annual Income terkadang memiliki outlier yang lumayan besar, disini kita melakukan limit sebesar 300000. Ini bertujuan agar kita bisa melihat tren dengan lebih jelas.

### Debt-to-income Ratio
"""

plt.figure(figsize=(10, 6))
sns.histplot(df['dti'], kde=True, color='purple')
plt.title('Debt to Income Ratio Distribution')
plt.xlabel('DTI')
plt.ylabel('Frequency')
plt.show()

"""### Term"""

plt.figure(figsize=(10, 6))
sns.countplot(x='term', data=df)
plt.title('Loan Term Distribution')
plt.xlabel('Term')
plt.ylabel('Count')
plt.show()

"""### Loan Grade"""

plt.figure(figsize=(12, 8))
sns.countplot(y='grade', data=df, order=sorted(df['grade'].unique()))
plt.title('Loan Grades Distribution')
plt.xlabel('Count')
plt.ylabel('Grade')
plt.show()

plt.figure(figsize=(14, 10))
sns.countplot(y='sub_grade', data=df, order=sorted(df['sub_grade'].unique()))
plt.title('Loan Sub-Grades Distribution')
plt.xlabel('Count')
plt.ylabel('Sub-Grade')
plt.show()

"""## Bivariate Analysis

### Loan Amount vs Annual Income
"""

df['income_category'] = pd.cut(df['annual_inc'], bins=[0, 50000, 100000, 150000, 200000, 250000, np.inf], labels=['0-50k', '50k-100k', '100k-150k', '150k-200k', '200k-250k', '250k+'])

plt.figure(figsize=(12, 8))
sns.boxplot(x='income_category', y='loan_amnt', hue='loan_status', data=df)
plt.title('Loan Amount Distribution Across Income Categories')
plt.xlabel('Annual Income Category')
plt.ylabel('Loan Amount')
plt.xticks(rotation=45)
plt.legend(title='Loan Status')
plt.show()

"""Interest Rates vs Loan Status"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='loan_status', y='int_rate', data=df)
plt.title('Interest Rate Distribution by Loan Status')
plt.xlabel('Loan Status')
plt.ylabel('Interest Rate')
plt.show()

"""### Interest Rate vs. Loan Status"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='loan_status', y='int_rate', data=df)
plt.title('Interest Rate Distribution by Loan Status')
plt.xlabel('Loan Status')
plt.ylabel('Interest Rate')
plt.show()

"""### Debt-to-Income Ratio vs. Loan Status"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='loan_status', y='dti', data=df)
plt.title('Debt-to-Income Ratio by Loan Status')
plt.xlabel('Loan Status')
plt.ylabel('Debt-to-Income Ratio')
plt.show()

"""### Employment Length vs. Loan Status"""

plt.figure(figsize=(12, 8))
sns.countplot(x='emp_length', hue='loan_status', data=df, order=['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years'])
plt.title('Loan Status by Employment Length')
plt.xlabel('Employment Length')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Loan Status')
plt.show()

df['emp_length_numeric'] = df['emp_length'].replace({
    '< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4,
    '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9,
    '10+ years': 10, np.nan: -1
}).astype(int)

bins = [-2, 2, 9, float('inf')]
labels = ['Unknown/Short-term (<3 years)', 'Medium-term (3-9 years)', 'Long-term (10+ years)']
df['employment_length_binned'] = pd.cut(df['emp_length_numeric'], bins=bins, labels=labels)


plt.figure(figsize=(12, 8))
sns.countplot(x='employment_length_binned', hue='loan_status', data=df)
plt.title('Loan Status Distribution by Binned Employment Length')
plt.xlabel('Binned Employment Length')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Loan Status')
plt.show()

grouped = df.groupby('employment_length_binned')['loan_status'].value_counts(normalize=True).rename('proportion').reset_index()


plt.figure(figsize=(12, 8))
sns.barplot(x='employment_length_binned', y='proportion', hue='loan_status', data=grouped)
plt.title('Proportional Distribution of Loan Statuses by Binned Employment Length')
plt.xlabel('Binned Employment Length')
plt.ylabel('Proportion')
plt.xticks(rotation=45)
plt.legend(title='Loan Status', loc='upper right', bbox_to_anchor=(1.25, 1))
plt.show()

"""### Analisis Berdasarkan State Peminjam"""

import plotly.express as px

state_counts = df['addr_state'].value_counts().reset_index()
state_counts.columns = ['state', 'count']

fig = px.choropleth(state_counts,
                    locations='state',
                    locationmode="USA-states",
                    color='count',
                    color_continuous_scale='Blues',
                    scope="usa",
                    title='Loan Frequencies by State')
fig.update_layout(margin={"r":0,"t":30,"l":0,"b":0})
fig.show()

import plotly.express as px

average_loan_by_state = df.groupby('addr_state')['loan_amnt'].mean().reset_index()
average_loan_by_state.columns = ['state', 'average_loan_amount']

fig = px.choropleth(average_loan_by_state,
                    locations='state',
                    locationmode="USA-states",
                    color='average_loan_amount',
                    color_continuous_scale='Viridis',
                    scope="usa",
                    title='Average Loan Amount by State')
fig.update_layout(margin={"r":0,"t":30,"l":0,"b":0})
fig.show()

"""# Data Preparation

## Feature Engineering
"""

df_clean.columns

df_clean.head()

"""Membuat beberapa fitur baru seperti Loan Age dan Credit History Length untuk memperkuat model"""

from datetime import datetime

df_clean['issue_d'] = pd.to_datetime(df_clean['issue_d'], format='%b-%y')
df_clean['earliest_cr_line'] = pd.to_datetime(df_clean['earliest_cr_line'], format='%b-%y')
df_clean['last_pymnt_d'] = pd.to_datetime(df_clean['last_pymnt_d'], format='%b-%y')

# 1. Loan Age in months
df_clean['loan_age_months'] = ((pd.to_datetime('today') - df_clean['issue_d']) / np.timedelta64(1, 'M'))
df_clean['loan_age_months'] = df_clean['loan_age_months'].fillna(0).astype(int)

# 2. Credit History Length
df_clean['credit_history_length'] = ((df_clean['issue_d'] - df_clean['earliest_cr_line']) / np.timedelta64(1, 'Y'))
df_clean['credit_history_length'] = df_clean['credit_history_length'].fillna(0).astype(int)

# 3. Months since Last Payment
df_clean['months_since_last_pymnt'] = ((pd.to_datetime('today') - df_clean['last_pymnt_d']) / np.timedelta64(1, 'M'))
df_clean['months_since_last_pymnt'] = df_clean['months_since_last_pymnt'].fillna(0).astype(int)

# 4. Debt-to-Income Ratio Adjusted
df_clean['dti_adjusted'] = (df_clean['loan_amnt'] / df_clean['annual_inc']) * df_clean['dti']
df_clean['dti_adjusted'] = df_clean['dti_adjusted'].fillna(0)

df_clean[['loan_age_months', 'credit_history_length', 'months_since_last_pymnt', 'dti_adjusted']].head()

"""### Feature Selection"""

columns_to_drop = ['member_id', 'title', 'issue_d', 'earliest_cr_line', 'last_pymnt_d']
df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')


df_clean['term'] = df_clean['term'].str.strip().str.replace(' months', '').astype(int)


df_clean.head()

df_clean['loan_status'].value_counts()

status_map = {
    "Current": "Good",
    "Fully Paid": "Good",
    "Charged Off": "Bad",
    "Late (31-120 days)": "Bad",
    "In Grace Period": "Bad",
    "Does not meet the credit policy. Status:Fully Paid": "Good",
    "Late (16-30 days)": "Bad",
    "Default": "Bad",
    "Does not meet the credit policy. Status:Charged Off": "Bad"
}

df_clean['loan_status'] = df_clean['loan_status'].map(status_map)
print(df_clean['loan_status'].value_counts())

threshold = 0.5
df_clean = df_clean.dropna(thresh=int(threshold * len(df_clean)), axis=1)

df_clean.info()

from scipy.stats import chi2_contingency
from scipy.stats import f_oneway

df_for_anova = df_clean.copy()

for col in df_for_anova.select_dtypes(include=['float64', 'int64']).columns:
    if df_for_anova[col].isna().any():
        median_value = df_for_anova[col].median()
        df_for_anova[col].fillna(median_value, inplace=True)

categorical_cols = df_for_anova.select_dtypes(include=['object', 'category']).columns
numerical_cols = df_for_anova.select_dtypes(include=['float64', 'int64']).columns

chi2_results = {}
anova_results = {}


for col in categorical_cols:
    if df_for_anova[col].isna().any():
        mode_value = df_for_anova[col].mode()[0]
        df_for_anova[col].fillna(mode_value, inplace=True)

    contingency_table = pd.crosstab(df_for_anova[col], df_for_anova['loan_status'])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    chi2_results[col] = p


for col in numerical_cols:
    groups = df_for_anova.groupby('loan_status')[col]
    if len(groups) > 1:
        anova_result = f_oneway(groups.get_group('Good'), groups.get_group('Bad'))
        anova_results[col] = anova_result.pvalue


print("Chi-squared Test Results:")
for feature, p_value in chi2_results.items():
    print(f"{feature}: p-value = {p_value}")

print("\nANOVA Test Results:")
for feature, p_value in anova_results.items():
    print(f"{feature}: p-value = {p_value}")

features_to_drop = ['acc_now_delinq', 'tot_coll_amt', 'application_type']
df_clean = df_clean.drop(columns=features_to_drop, errors='ignore')



"""# Data Modelling

## Leakage Testing
"""

#rf = RandomForestClassifier(n_estimators=100, random_state=42)
#rf.fit(X_train, y_train)
#y_pred_rf = rf.predict(X_test)
#print("Random Forest Performance:")
#print(classification_report(y_test, y_pred_rf))

# feature_importances = rf.feature_importances_

# features = pd.Series(feature_importances, index=X_train.columns)


# features_sorted = features.sort_values(ascending=False).head(10)

# plt.figure(figsize=(10, 8))
# sns.barplot(x=features_sorted, y=features_sorted.index)
# plt.title('Feature Importance')
# plt.xlabel('Importance Score')
# plt.ylabel('Features')
# plt.show()



from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


X = df_clean.drop('loan_status', axis=1)
y = df_clean['loan_status'].apply(lambda x: 1 if x == 'Good' else 0)


X = pd.get_dummies(X, drop_first=True)
X.fillna(X.mean(), inplace=True)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

df_clean.info()

leaky_features = ['collection_recovery_fee', 'recoveries', 'total_rec_prncp',
                  'last_pymnt_amnt', 'total_pymnt', 'total_pymnt_inv',
                  'out_prncp', 'out_prncp_inv']


X_train_reduced = X_train.drop(columns=leaky_features, errors='ignore')
X_test_reduced = X_test.drop(columns=leaky_features, errors='ignore')


#rf_reduced = RandomForestClassifier(n_estimators=100, random_state=42)
#rf_reduced.fit(X_train_reduced, y_train)


#y_pred_rf_reduced = rf_reduced.predict(X_test_reduced)
#print("Revised Random Forest Performance:")
#print(classification_report(y_test, y_pred_rf_reduced))

from sklearn.metrics import accuracy_score
#print(accuracy_score(y_test, y_pred_rf_reduced))

"""## Logistic Regression"""

import gc
del df
gc.collect()

import gc
del df_for_anova
gc.collect()

X_train_fix = X_train_reduced.astype('float32')
X_test_fix = X_test_reduced.astype('float32')

log_reg_fix = LogisticRegression(max_iter=100, solver='sag')
log_reg_fix.fit(X_train_fix, y_train)

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

y_pred_log = log_reg_fix.predict(X_test_reduced)

print(classification_report(y_test, y_pred_log))
print(accuracy_score(y_test, y_pred_log))

import xgboost as xgb

xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')

X_train_reduced.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_train_reduced.columns]
X_test_reduced.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_test_reduced.columns]


xgb_model.fit(X_train_reduced, y_train)


y_pred_xgb = xgb_model.predict(X_test_reduced)


print("XGBoost Performance with Reduced Features:")
print(classification_report(y_test, y_pred_xgb))

print(accuracy_score(y_test, y_pred_xgb))